---
title: "Bayesova statistika: zakljucna seminarska naloga 2020"
author: "Tina Razic"
fontsize: 12pt
output:
  pdf_document:
    number_sections: yes
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = T, fig.width = 8, fig.height = 5, out.width="0.8\\textwidth")
```

# Pri multipli linearni regresiji preko simulacij primerjajte Bayesov pristop s frekventisticnim.

```{r warning=FALSE}
library(R2BayesX)
library(matrixStats)
library(basicMCMCplots)
library(coda)
library(GMCM)
library(yardstick)
library(nimble)
library(abe)
library(dplyr)
```

Napisemo funckijo, ki bo simulirala frekventisticni in bayesovski pristop za vsak simulacijski scenarij. Sprejme stevilo simulacij in parameter distribution, ki pove funckiji kateri scenarij naj simulira. 

```{r}
# Dolocimo beta koeficiente
b0 <- 1.89
b1 <- 0.9 
b2 <- 1
b3 <- 2
b4 <- 4
b5 <- 0
  
beta <- c(b0,b1,b2,b3,b4,b5)
```

```{r eval=FALSE}
sim.lm.bayesx <-  function(n, distribution){
  
  # Dolocimo beta koeficiente
  b0 <- 1.89
  b1 <- 0.9 
  b2 <- 1
  b3 <- 2
  b4 <- 4
  b5 <- 0
  
  beta <- c(b0,b1,b2,b3,b4,b5)
  
  # Postavimo tabele, v katere bomo shranjevali koeficiente 
  # in standardne napake.
  
  names = c("Intercept", "x1","x2","x3","x4","x5")
  lm.coeff.frame <- as.data.frame(matrix(0, ncol = 6, nrow = n))
  lm.std.error.frame <- as.data.frame(matrix(0, ncol = 6, nrow = n))
  
  bayes.coeff.frame <- as.data.frame(matrix(0, ncol = 6, nrow = n))
  bayes.std.error.frame <- as.data.frame(matrix(0, ncol = 6, nrow = n))
  
  colnames(lm.coeff.frame) <- names
  colnames(lm.std.error.frame) <- names
  colnames(bayes.coeff.frame) <- names
  colnames(bayes.std.error.frame) <- names
  
  # for zanka za simulacije 
  for (i in 1:n) {
    # Definiramo neodvisne spremenljivke, kot je definirano v navodilih.
    x0 <- rep(1,100)
    x1 <- rnorm(100) + 2
    x2 <- rnorm(100,2, 1)
    x3 <- rbinom(100, 1, 0.9)
    x4 <- runif(100, 0,1)
    x5 <- rbinom(100, 10, 0.2)
    
    x <- data.frame(x1, x2, x3, x4, x5)
  
    if (distribution == "norm.small"){
      # prvi scenarij, napaka porazdeljena normalno z majhno napako
      std <- 0.5
      e <- rnorm(100,0,std)}
    else if (distribution == "norm.big"){
      # drugi scenarij, napaka porazdeljena normalno z veliko napako
      std <- 2
      e <- rnorm(100,0,std)}
    else{
      # tretji scenarij, napaka porazdeljena asimetricno hi kvadrat
      e <- rchisq(100, 1)}
    
    # ko imamo doloceno napako, lahko zgradimo y 
    y <- b0*x0 + b1*x1 + b2*x2 + b3*x3 + b4*x4 + b5*x5 + e
    
    # podatke sestavimo v tabelo
    data = cbind(y, x)
    
    # lm
    fit.lm <- lm(y ~ ., data = data)
    lm.coeff <- summary(fit.lm)$coef[,1]
    lm.std.error <- summary(fit.lm)$coef[,2]
    lm.coeff.frame[i,] <- lm.coeff
    lm.std.error.frame[i, ] <- lm.std.error
    
    # bayesx
    fit.bayesx <- bayesx(y ~ x1 + x2 + x3 + x4 + x5, data, family = "gaussian", method = "MCMC")
    bayesx.coeff <-fit.bayesx$fixed.effects[,1]
    bayesx.std.error <- fit.bayesx$fixed.effects[,2]
    bayes.coeff.frame[i,] <- bayesx.coeff
    bayes.std.error.frame[i,] <- bayesx.std.error
  }
  return(list(lm.coeff.frame,lm.std.error.frame, bayes.coeff.frame, bayes.std.error.frame))
}

n = 1000
first.scenario <- sim.lm.bayesx(n, "norm.small")
second.scenario <- sim.lm.bayesx(n,"norm.big")
third.scenario <- sim.lm.bayesx(n, "chisq")
```

```{r eval=FALSE}
dump(c("first.scenario", "second.scenario", "third.scenario"), file = "dump.rezultati.r")
```

Privzete nastavitve funckije bayesx so primerne za nase potrebe, zato smo lahko vse tri scenarije enostavno spravili v eno funkcijo. Rezultate funckije shranimo v drugo datoteko zaradi dolgotrajnosti simulacij. 

```{r}
source("dump.rezultati.r")
# first scenario
lm.coeff.1 <- first.scenario[[1]]
lm.std.error.1 <- first.scenario[[2]]
bayesx.coeff.1 <- first.scenario[[3]]
bayesx.std.error.1 <- first.scenario[[4]]

# second scenario
lm.coeff.2 <- second.scenario[[1]]
lm.std.error.2 <- second.scenario[[2]]
bayesx.coeff.2 <- second.scenario[[3]]
bayesx.std.error.2 <- second.scenario[[4]]

# third scenario
lm.coeff.3 <- third.scenario[[1]]
lm.std.error.3 <- third.scenario[[2]]
bayesx.coeff.3 <- third.scenario[[3]]
bayesx.std.error.3 <- third.scenario[[4]]
```

Z zgornjimi simulacijami smo za vsak simulacijski scenarij dobili tabele ocen za koeficiente in njihove standardne napake. Sedaj lahko analiziramo za vsak scenarij pristranost, standardno napako in srednjo kvadratno napako.

## 1. scenarij: normalno porazdeljena napaka z majhno varianco

### Pristranost

Naredimo povprecje ocen koeficientov za potrebe izracuna pristranosti.

```{r}
# lm
avg.lm.coeff.1 <- colMeans(lm.coeff.1)

# bayesx
avg.bayesx.coeff.1 <- colMeans(bayesx.coeff.1)
```

Naredimo vektor pristranosti velikosti 6 za oba pristopa. Komponenta k pomeni pristranost koeficienta $\beta_k$.

```{r}
bias.lm.beta.1 <- avg.lm.coeff.1 - beta
bias.bayesx.beta.1 <- avg.bayesx.coeff.1 - beta

bias.lm.beta.1
bias.bayesx.beta.1
```

Pri frekventisticnem in bayesovskem pristopu so vrednosti pristanosti zelo majhne. Torej je povprecna ocena koeficienta zelo blizu pravi vrednosti. Ce oznacimo s $\theta$ spremenljivko, ki nas zanima, napisemo pristranost s formulo:

$$
pristranost = E(\theta) - \theta
$$

Prav tako, ce si pogledamo razlike med obema pristopoma, so razlike zanemarljive:

```{r}
bias.diff.1 <- bias.lm.beta.1 - bias.bayesx.beta.1
bias.diff.1
```

### Standardna napaka in srednja kvadratna napaka

Oznacimo s $\theta$ spremenljivko, ki nas zanima. Srednjo kvadratno napako lahko izracunamo na naslednji nacin:

$$
{\displaystyle \operatorname {MSE} ({\hat {\theta }})=\operatorname {Var} _{\theta }({\hat {\theta }})+\operatorname {Bias} ({\hat {\theta }},\theta )^{2}.}
$$

```{r}
standard.error.lm.coeff.1 <- sapply(lm.coeff.1, sd)/sqrt(sapply(lm.coeff.1, effectiveSize))
standard.error.bayesx.coeff.1 <- sapply(bayesx.coeff.1, sd)/sqrt(sapply(bayesx.coeff.1, effectiveSize))
standard.error.lm.coeff.1
standard.error.bayesx.coeff.1

variance.lm.coeff.1 <- sapply(lm.coeff.1, var)
variance.bayesx.coeff.1 <- sapply(bayesx.coeff.1, var)

skn.lm.coeff.1 <- sqrt(bias.lm.beta.1^2 + variance.lm.coeff.1^2)
skn.bayesx.coeff.1 <- sqrt(bias.bayesx.beta.1^2 + variance.bayesx.coeff.1^2)
skn.lm.coeff.1
skn.bayesx.coeff.1
```

Oba pristopa zelo podobno pokazeta, razlikujeta se sele na 4 decimalnem mestu. Standardna napaka in srednja kvadratna napaka so zelo majhne pri vseh koeficientih. To je posledica velikega stevila simulacij. Verjetno bi lahko pri vecjem stevilu simulacij ldobili se manjse napake, a zaradi zmogljivosti racunalnika sem ohranila 1000 simulacij v vseh treh primerih. 


### Povprecje ocenjenih standardnih napak

Povprecimo ocene standardnih napak za vsak koeficient posebej.

```{r}
# lm
avg.lm.std.error.1 <- colMeans(lm.std.error.1)
avg.lm.std.error.1

# bayesx
avg.bayesx.std.error.1 <- colMeans(bayesx.std.error.1)
avg.bayesx.std.error.1
```

Povprecja standardnih napak so si zelo blizu za oba pristopa pri vseh koeficiente. Poglejmo se vektor razlik med pristopoma:

```{r}
diff.std.error.1 <- abs(avg.lm.std.error.1 - avg.bayesx.std.error.1)
diff.std.error.1
```

Vidimo razlike sele na tretji oziroma 4 decimalki. Tudi iz povprecja standardnih napak vidimo, da sta oba pristopa pri scenariju z normalno porazdeljeno napako z majhno varianco v povprecju zelo dobro ocenila koeficiente modela, ki so imeli majhen vpliv, pri tistih koeficentih z vecjim vplivom pa je standardna napaka malo vecja.

## 2. scenarij: normalno porazdeljena napaka z veliko varianco

### Pristranost

Naredimo povprecje ocen za ocene koeficientov za potrebe izracuna pristranosti.

```{r}
# lm
avg.lm.coeff.2 <- colMeans(lm.coeff.2)
avg.lm.std.error.2 <- colMeans(lm.std.error.2)

# bayesx
avg.bayesx.coeff.2 <- colMeans(bayesx.coeff.2)
avg.bayesx.std.error.2 <- colMeans(bayesx.std.error.2)
```

Naredimo vektor pristranosti velikosti 6 za oba pristopa. Komponenta k pomeni pristranost koeficienta $\beta_k$.

```{r}
bias.lm.beta.2 <- avg.lm.coeff.2 - beta
bias.bayesx.beta.2 <- avg.bayesx.coeff.2 - beta

bias.lm.beta.2
bias.bayesx.beta.2
```

Pri frekventisticnem in bayesovskem pristopu so vrednosti pristanosti majhne, najmanjso vrednost dobimo pri koeficentu, ki je imel najvecji vpliv na spremenljivko $y$. Prav tako je zanimivo, da je vrednosti pristranosti negativna, to pomeni, da je model napovedal manjso vrednost kot je v resnici. Pristranosti so v tem modelu malo vecje kot pri prvem scenarijum le pri koeficentu $\beta_4$ je pristarnost manjsa. Poglejmo si se razliko med obema pristopoma.

```{r}
bias.diff.2 <- bias.lm.beta.2 - bias.bayesx.beta.2
bias.diff.2
```

Razlike so zelo majhne.

### Standardna napaka in srednja kvadratna napaka

```{r}
standard.error.lm.coeff.2 <- sapply(lm.coeff.2, sd)/sqrt(sapply(lm.coeff.2, effectiveSize))
standard.error.bayesx.coeff.2 <- sapply(bayesx.coeff.2, sd)/sqrt(sapply(bayesx.coeff.2, effectiveSize))
standard.error.lm.coeff.2
standard.error.bayesx.coeff.2

variance.lm.coeff.2 <- sapply(lm.coeff.2, var)
variance.bayesx.coeff.2 <- sapply(bayesx.coeff.2, var)

skn.lm.coeff.2 <- sqrt(bias.lm.beta.2^2 + variance.lm.coeff.2^2)
skn.bayesx.coeff.2 <- sqrt(bias.bayesx.beta.2^2 + variance.bayesx.coeff.2^2)
skn.lm.coeff.2
skn.bayesx.coeff.2
```

Oba pristopa zelo podobno pokazeta. Standardne napake in srednja kvadratna napaka so pri obeh pristopih vecje kot pri prvem scenariju. Pristranosti so se vedno majhne, zato k veliki srednje kvadratni napaki prispeva varianca koeficientov. 

### Povprecje ocenjenih standardnih napak

Povprecimo ocene standardnih napak za vsak koeficient posebej.

```{r}
# lm
avg.lm.std.error.2 <- colMeans(lm.std.error.2)
avg.lm.std.error.2

# bayesx
avg.bayesx.std.error.2 <- colMeans(bayesx.std.error.2)
avg.bayesx.std.error.2
```

Poglejmo vektor razlik:

```{r}
diff.std.error.2 <- abs(avg.lm.std.error.2 - avg.bayesx.std.error.2)
diff.std.error.2
```

Povprecje ocenjenih standardnih napak je pri obeh pristopih vecje kot standardne napake pri drugi tocki. Prav tako so standardne napake veliko vecje kot tiste v prvem scenariju. Ponovno opazimo minimalno razliko med obema modeloma. Morda bo najbolj zanimiv tretji scenarij, kjer predpostavke modelov niso izpolnjene. Tako lahko preverimo, kateri je bolj robusten.

## 3. scenarij: asimetricno porazdeljena napaka

### Pristranost

Naredimo povprecje ocen za ocene koeficientov za potrebe izracuna pristranosti.

```{r}
# lm
avg.lm.coeff.3 <- colMeans(lm.coeff.3)
avg.lm.std.error.3 <- colMeans(lm.std.error.3)

# bayesx
avg.bayesx.coeff.3 <- colMeans(bayesx.coeff.3)
avg.bayesx.std.error.3 <- colMeans(bayesx.std.error.3)
```

Naredimo vektor pristranosti velikosti 6 za oba pristopa. Komponenta k pomeni pristranost koeficienta $\beta_k$.

```{r}
bias.lm.beta.3 <- avg.lm.coeff.3 - beta
bias.bayesx.beta.3 <- avg.bayesx.coeff.3 - beta

bias.lm.beta.3
bias.bayesx.beta.3
```

Pristranosti so majhne in vecinoma negativne razen pri spremenljivki z najvecjim vplivom (x4).Poglejmo si razlike med obema pristopoma.

```{r}
bias.diff.3 <- bias.lm.beta.3 - bias.bayesx.beta.3
bias.diff.3
```

Med pristopoma ponovno ni vecjih razlik. Lahko recemo, da oba enako reagirata na krsenje predpostavke simetricnosti, vsaj kar se tice meritve pristranosti.

### Standardna napaka in srednja kvadratna napaka

```{r}
standard.error.lm.coeff.3 <- sapply(lm.coeff.3, sd)/sqrt(sapply(lm.coeff.3, effectiveSize))
standard.error.bayesx.coeff.3 <- sapply(bayesx.coeff.3, sd)/sqrt(sapply(bayesx.coeff.3, effectiveSize))
standard.error.lm.coeff.3
standard.error.bayesx.coeff.3

variance.lm.coeff.3 <- sapply(lm.coeff.3, var)
variance.bayesx.coeff.3 <- sapply(bayesx.coeff.3, var)

skn.lm.coeff.3 <- sqrt(bias.lm.beta.3^2 + variance.lm.coeff.3^2)
skn.bayesx.coeff.3 <- sqrt(bias.bayesx.beta.3^2 + variance.bayesx.coeff.3^2)
skn.lm.coeff.3
skn.bayesx.coeff.3
```

Standardne napake so vecje kot v prvem scenariju a manjse kot v drugem scenariju.

### Povprecje ocenjenih standardnih napak

Povprecimo ocene standardnih napak za vsak koeficient posebej.

```{r}
# lm
avg.lm.std.error.3 <- colMeans(lm.std.error.3)
avg.lm.std.error.3

# bayesx
avg.bayesx.std.error.3 <- colMeans(bayesx.std.error.3)
avg.bayesx.std.error.3
```

Poglejmo vektor razlik:

```{r}
diff.std.error.3 <- abs(avg.lm.std.error.3 - avg.bayesx.std.error.3)
diff.std.error.3
```

Povprecje standardnih napak je ponovno veliko vecje kot izracun standardne napake pri drugi tocki, vec kot trikrat vecje. 

# Primerjajte metode za izbor spremenljivk (variable selection) na simuliranih podatkih

Pripravimo podatke za vsak scenarij, tako da dodamo 5 spremenjljivk, ki nimajo efekta. Definiramo novo funkcijo, ki dodeli ustrezno napako in zgradi y, vrne pa tabelo simuliranih podatkov.

```{r}
sim.lm.bayesx.2 <-  function(distribution){
    
    # Dolocimo beta koeficiente
    b0 <- 1.89
    b1 <- 0.9 
    b2 <- 1
    b3 <- 2
    b4 <- 4
    b5 <- 0
    
    beta <- c(b0,b1,b2,b3,b4,b5)
    
    b6 = 0
    b7 = 0
    b8 = 0
    b9 = 0
    b10 = 0
    
    beta.2 <- c(b0, b1, b2, b3, b4, b5, b6, b7, b8, b9, b10)
    
    # Definiramo neodvisne spremenljivke, kot je definirano v navodilih.
    x0 <- rep(1,100)
    x1 <- rnorm(100) + 2
    x2 <- rnorm(100,2, 1)
    x3 <- rbinom(100, 1, 0.9)
    x4 <- runif(100, 0,1)
    x5 <- rbinom(100, 10, 0.2)
    
    x <- data.frame(x1, x2, x3, x4, x5)
    
    x6 <- runif(100)
    x7 <- runif(100)
    x8 <- runif(100)
    x9 <- runif(100)
    x10 <- runif(100)
    
    x.2 <- cbind(x, x6, x7, x8, x9, x10)
    
    # Dolocimo porazdelitev napake
    if (distribution == "norm.small"){
      # prvi scenarij, napaka porazdeljena normalno z majhno napako
      std <- 0.5
      e <- rnorm(100,0,std)}
    else if (distribution == "norm.big"){
      # drugi scenarij, napaka porazdeljena normalno z veliko napako
      std <- 2
      e <- rnorm(100,0,std)}
    else{
      # tretji scenarij, napaka porazdeljena asimetricno hi kvadrat
      e <- rchisq(100, 1)}
    
    # Zgradimo y 
    y <- b0*x0 + b1*x1 + b2*x2 + b3*x3 + b4*x4 + b5*x5  
              + b6*x6 + b7*x7 + b8*x8 + b9*x9 + b10*x10 + e
    
    # podatke sestavimo v tabelo
    data = cbind(y, x.2)
    
  return(data)
}

first.scenario.2.data <- sim.lm.bayesx.2("norm.small")
second.scenario.2.data <- sim.lm.bayesx.2("norm.big")
third.scenario.2.data <- sim.lm.bayesx.2("chisq")
```

## Uporaba indikatorskih funckij

Naredimo funckijo, ki naredi Bayesov izbor spremenljivk z uporabo indikatorskih funkcij ob regresijskih koeficientih.

```{r}
indicators <- function(data){
  X <- data[, 2:11]
  X <- sweep(X, 2, colMeans(X), FUN="-") #centriramo
  #  centriramo
  
  codeSelect <- nimbleCode({
    sigma ~ dunif(0, 20)
    psi ~ dunif(0,1) #  to je nas hiperparameter
    
    beta0 ~ dnorm(0, sd=100)
    for(i in 1:p) {
      z[i] ~ dbern(psi) #indikator za vsak koeficient
      beta[i] ~ dnorm(0, sd = 100)
      zbeta[i] <- z[i] * beta[i] #  produkt z in bete, z je bernoullijeva, torej pokaze 0 ali 1
    }
    for(i in 1:N) {
      y[i] ~ dnorm(beta0 + inprod(X[i, 1:p], zbeta[1:p]), sd = sigma)
    }
  })
  
  N <- dim(X)[1]
  p <- dim(X)[2]
  
  constantsSelect <- list(N = N, p = p)
  
  initsSelect <- list(sigma = 1, psi = 0.5, beta0 = 0,
                      beta = rnorm(p),
                      z = sample(c(0, 1), p, replace = TRUE))
  
  dataSelect <- list(y = data$y, X = X)
  
  RmodelRJ <- nimbleModel(code = codeSelect, constants = constantsSelect,
                          inits = initsSelect, data = dataSelect)
  
  confRJ <- configureMCMC(RmodelRJ)
  
  confRJ$addMonitors('z') #zapomni si tudi z
  
  configureRJ(confRJ,
              targetNodes = 'beta',
              indicatorNodes = 'z',
              control = list(mean = 0, scale = .2))
  confRJ$printSamplers()
  
  RmcmcRJ <- buildMCMC(confRJ)
  
  CmodelRJ <- compileNimble(RmodelRJ)
  
  CmcmcRJ <- compileNimble(RmcmcRJ, project = CmodelRJ)
  
  system.time(
    samplesRJ <- runMCMC(CmcmcRJ, niter = 12000, nburnin = 2000)
  )
  
  round(samplesSummary(samplesRJ), 2)
  
  print(effectiveSize(samplesRJ))
  
  return(round(samplesSummary(samplesRJ), 2))
  
}
```

```{r}
indicators(first.scenario.2.data)
```

Uporaba funckije na podatkih iz prvega scenarija je zelo uspesna. ce pogledamo vektor z, je funckija tocno izbrala katere spremenljivke so bile vkljucene in katere ne. Tudi ocene za beta so pri $\beta_{1},\beta_{2}, \beta_{3}, \beta_{4}$ tocne, pri spremenljivkah, ki niso bile vkljucene oziroma so imele koeficient 0, pa funckija tudi pokaze nicelne vrednosti, le pri enem koeficientu zataji, vendar pokaže velik standardni odklono.

```{r}
indicators(second.scenario.2.data)
```

Pri drugem scenariju funckija pravilno izloci vse spremenljivke z beta koeficientom 0, vendar je povprecje pri beta8, beta9 in beta10 zgreseno z velikim standardnim odklonom.

```{r}
indicators(third.scenario.2.data)
```

Funckija na podatkih iz tretjega scenarija v vektorju z ponovno pravilno izbere spremenljivke. Ocene za beta koeficiente so priblizno v redu za spremenljivke, ki so vkljucene v model, za spremenljivke, ki imajo beta koeficient nic pa samo pri dveh pokaze nicelne vrednosti.

Razlika med scenariji z uporabo indikatorskih funckij se je na nasih podatkih pokazala le pri koeficientih beta, ki so imeli ničelno vrednost. Pri vseh scenarijih pa je bila izbira spremenljivk prava.

## Backward selection preko AIC, preko BIC in preko p vrednosti s stopnjo znacilnosti $\alpha = 0.2$

### 1. scenarij

```{r warning=FALSE}
fit = lm(y ~ . , data = first.scenario.2.data, x = TRUE, y = TRUE)

# AIC
abe.fit.boot.AIC <- abe.boot(fit, criterion = "AIC", data = first.scenario.2.data, tau = Inf, exp.beta = FALSE, num.boot = 200, type.boot = "bootstrap")

# BIC
abe.fit.boot.BIC <- abe.boot(fit, criterion = "BIC", data = first.scenario.2.data, tau = Inf, exp.beta = FALSE, num.boot = 200, type.boot = "bootstrap")

# preko vrednosti p
abe.fit.boot.p <- abe.boot(fit, criterion = "alpha", data = first.scenario.2.data, tau = Inf, exp.beta = FALSE, num.boot = 200, type.boot = "bootstrap")


plot(abe.fit.boot.AIC, type.plot = "variables",  variable = abe.fit.boot.AIC$all.vars,
     horiz = TRUE, las = 1, sub = "AIC")
plot(abe.fit.boot.BIC, type.plot = "variables",  variable = abe.fit.boot.BIC$all.vars,
       horiz = TRUE, las = 1, sub = "BIC")
plot(abe.fit.boot.p, type.plot = "variables",  variable = abe.fit.boot.p$all.vars,
       horiz = TRUE, las = 1, sub = "p.value")
```

Vsi trije grafi vkljucijo zagotovo prve stiri spremenljivke. Kriterij BIC predpise spremenljivkam, ki imajo koeficient 0 najmanjso vrednost izmed vseh treh kriterijev. 

### 2. scenarij

```{r warning=FALSE}
fit.2 = lm(y ~ . , data = second.scenario.2.data, x = TRUE, y = TRUE)

# AIC
abe.fit.boot.AIC.2 <- abe.boot(fit.2, criterion = "AIC", data = second.scenario.2.data, tau = Inf, exp.beta = FALSE, num.boot = 200, type.boot = "bootstrap")

# BIC
abe.fit.boot.BIC.2 <- abe.boot(fit.2, criterion = "BIC", data = second.scenario.2.data, tau = Inf, exp.beta = FALSE, num.boot = 200, type.boot = "bootstrap")

# preko vrednosti p
abe.fit.boot.p.2 <- abe.boot(fit.2, criterion = "alpha", data = second.scenario.2.data, tau = Inf, exp.beta = FALSE, num.boot = 200, type.boot = "bootstrap")


plot(abe.fit.boot.AIC.2, type.plot = "variables",  variable = abe.fit.boot.AIC.2$all.vars,
     horiz = TRUE, las = 1, sub = "AIC")
plot(abe.fit.boot.BIC.2, type.plot = "variables",  variable = abe.fit.boot.BIC.2$all.vars,
       horiz = TRUE, las = 1, sub = "BIC")
plot(abe.fit.boot.p.2, type.plot = "variables",  variable = abe.fit.boot.p.2$all.vars,
       horiz = TRUE, las = 1, sub = "p.value")
```


Na podatkih iz drugega scenarija metode ponovno izberejo stoodstotno spremenljivke, ki imajo koeficient razlicen od  nic. Kriterij BIC pa pokaze njamanjse vrednosti pri ostalih spremenljivkah. 

### 3. scenarij

```{r warning=FALSE}
fit.3 = lm(y ~ . , data = third.scenario.2.data, x = TRUE, y = TRUE)

# AIC
abe.fit.boot.AIC.3 <- abe.boot(fit.3, criterion = "AIC", data = third.scenario.2.data, tau = Inf, exp.beta = FALSE, num.boot = 200, type.boot = "bootstrap")

# BIC
abe.fit.boot.BIC.3 <- abe.boot(fit.3, criterion = "BIC", data = third.scenario.2.data, tau = Inf, exp.beta = FALSE, num.boot = 200, type.boot = "bootstrap")

# preko vrednosti p
abe.fit.boot.p.3 <- abe.boot(fit.3, criterion = "alpha", data = third.scenario.2.data, tau = Inf, exp.beta = FALSE, num.boot = 200, type.boot = "bootstrap")


plot(abe.fit.boot.AIC.3, type.plot = "variables",  variable = abe.fit.boot.AIC.3$all.vars,
     horiz = TRUE, las = 1, sub = "AIC")
plot(abe.fit.boot.BIC.3, type.plot = "variables",  variable = abe.fit.boot.BIC.3$all.vars,
       horiz = TRUE, las = 1, sub = "BIC")
plot(abe.fit.boot.p.3, type.plot = "variables",  variable = abe.fit.boot.p.3$all.vars,
       horiz = TRUE, las = 1, sub = "p.value")
```

Vse metode izberejo spremenljivke x1, x2, x3 in x4. 

Vse metode so se na vseh treh scenarijih odrezale zelo dobro. Zagotovo so izbrale spremenljivke, ki so bile vkljucene v nas zacetni model, kljub razlikam v varianci in porazdelitvi. 

# Izberite si neke podatke.

## a) Izbira podatkov

```{r}
data("iris")
head(iris)
str(iris)
```

Izberemo si podatke iz knjiznice programa R o vrstah in cvetovih roze petunike("iris"). Podatki imajo 150 enot in 5 spremenljivk: dolzino in sirino casnih listov ("sepal"), dolzina in sirina cvetnih listov ("petal") ter vrsto. Potrebovali smo podatki, ki imajo za eno spremenljivko nekaksne skupine, da bomo lahko nastavili hierarhicni model.

## b) Enostaven model

Proucevali bomo dolzino casnih listov v odvisnosti od ostalih spremenljivk. Smiselno se slisi, da je dolzina casnih listov povezana s sirino ter dolzino in sirino cvetnih listov. To bomo preverili z enostavnim modelom:
  
Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width

Bayesovski pristop s paketom nimble v katerem centriramo nase spremenljivke:
```{r}
code <- nimbleCode({
  beta0 ~ dnorm(0, sd = 100)
  beta1 ~ dnorm(0, sd = 100)
  beta2 ~ dnorm(0, sd = 100)
  beta3 ~ dnorm(0, sd = 100)
  sigma ~ dunif(0, 100)
  for(i in 1:n) {
    y[i] ~ dnorm(beta0 + beta1*x1[i] + beta2*x2[i] + beta3*x3[i], sd = sigma)
  }
})

# centriramo podatke
constants <- list(n = length(iris$Sepal.Length),
                  x1 = iris$Sepal.Width - mean(iris$Sepal.Width),
                  x2 = iris$Petal.Length - mean(iris$Petal.Length),
                  x3 = iris$Petal.Width - mean(iris$Petal.Width))

data <- list(y = iris$Sepal.Length)

inits <- list(beta0 = mean(iris$Sepal.Length),
              beta1 = 0,
              beta2 = 0,
              beta3 = 0,
              sigma = 1)

Rmodel <- nimbleModel(code, constants, data, inits)
conf <- configureMCMC(Rmodel)
conf$printSamplers()
```

```{r}
Rmcmc <- buildMCMC(conf)
Cmodel <- compileNimble(Rmodel)
Cmcmc <- compileNimble(Rmcmc, project = Cmodel)
samples <- runMCMC(Cmcmc, niter = 12000, nburnin = 2000)

samplesSummary(samples)
```

Iz analize koeficientov vidimo, da na dolzino casnih listov najbolj vpliva dolzina cvetnih listov. Pozitiven vpliv na dolzino ima tudi sirina casnega lista. Pri spremenljivki sirina casnega lista pa je koeficient negativen, torej ob ostalih nespremenjenih spremenljivkah velja sirsi cvetni list, krajsi casni list.

Poglejmo vzorec, ki ga dobimo z bayesovskim pristopom in ga narisimo:

```{r}
samplesPlot(samples)
```


```{r}
samplesPlot(samples, var = "beta1")
samplesPlot(samples, var = "beta2")
samplesPlot(samples, var = "beta3")
samplesPlot(samples, var = "sigma")
```

Vsi grafi so lepo zgosceni in nihajo dokaj enakomerno gor in dol v nekem omejenem obmocju. Poglejmo si par razlicnih verig.

```{r}
initsFunction <- function(){
  list(beta0 = rnorm(1),
       beta1 = rnorm(1),
       beta2 = rnorm(1),
       beta3 = rnorm(1),
       sigma = runif(1, min = 0, max = 10))
}


samplesList <- runMCMC(Cmcmc, niter = 12000, nburnin = 2000,
                          nchains = 3, inits = initsFunction)
```

```{r}
chainsPlot(samplesList)
```

Aposterirone porazdelitve na levi strani se relativno lepo prekrivajo.


## c) Hierarhicni model

Zdruzili bomo podatke po vrstah in za vsako vrsto imeli svoj parameter povprecja, ki bo simuliran iz normalne hiperapriorne porazdelitve s paremetroma mu in eta. Proucevali bomo ali je dolzina casnega lista odvisna od dolzine cvetnega lista:

Sepal.Length ~ Petal.Length

Tako imamo 4 hiperparametre (eta,mu, beta in etabeta) in 7 apriornih parametrov(mu1, mu2, mu3, beta1, beta2, beta3 in sigma).

```{r}
podatki <- iris %>% group_by(Species) %>% summarise(povprecje = mean(Sepal.Length), n=length(Sepal.Length), varianca = var(Sepal.Length))
str(podatki)
head(podatki)
```

```{r}
m <- length(podatki$Species)
n <- podatki$n

yMatrix <- matrix(NA, ncol = m, nrow = max(n))

for (j in 1:m) {
  yMatrix[1:n[j],j] <- iris[iris$Species ==podatki$Species[j],]$Sepal.Length
}

xMatrix <- matrix(NA, ncol = m, nrow = max(n))
for (j in 1:m) {
xMatrix[1:n[j],j] <- iris[iris$Species==podatki$Species[j],]$Petal.Length - mean(iris[iris$Species==podatki$Species[j],]$Petal.Length) #centriramo
}

code2 <- nimbleCode({
  mu ~ dnorm(0, sd = 100)
  eta ~ dunif(0, 100)
  sigma ~ dunif(0, 100)
  
  beta ~ dnorm(0, sd = 100)
  etaBeta ~ dunif(0, 100)
  
  for (j in 1:m) {
    muGroups[j] ~ dnorm(mu, sd = eta)
    betaGroups[j] ~ dnorm(beta, sd = etaBeta)
    for (i in 1:n[j]) {
      y[i, j] ~ dnorm(muGroups[j] + betaGroups[j] * x[i, j], sd = sigma);
    }
  }
})

constants2 <- list(m = m, n = n)

inits2 <- list(mu = mean(podatki$povprecje),
              eta = sd(podatki$povprecje),
              sigma = mean(sqrt(podatki$varianca)),
              muGroups = podatki$povprecje,
              betaGroups = rep(0, m),
              beta = 0,
              etaBeta = 1)

data2 <- list(y = yMatrix, x = xMatrix)
Rmodel2 <- nimbleModel(code = code2, constants = constants2,
                      inits = inits2, data = data2)
Rmodel2$initializeInfo()

conf2 <- configureMCMC(Rmodel2)
conf2$printMonitors()
```


```{r}
conf2$addMonitors('muGroups')
conf2$addMonitors('betaGroups')

Rmcmc2 <- buildMCMC(conf2)
Cmodel2 <- compileNimble(Rmodel2)
Cmcmc2 <- compileNimble(Rmcmc2, project = Cmodel2)
samples2 <- runMCMC(Cmcmc2, niter = 12000, nburnin = 4000)

samplesSummary(samples2)
```

V vseh treh skupinah vidimo pozitiven koeficiente beta, torej dolzina cvetnih listov pozitivno vpliva na dolzino casnih listov. Največji beta koeficient imamo pri skupini "virginica".Povprečja skupin pa se ujemajo s pravimi podatki. Poglejmo si se grafe vzorcev.

```{r}
samplesPlot(samples2, var = c("beta","betaGroups[2]"))
samplesPlot(samples2, var = c("mu","muGroups[1]"))
samplesPlot(samples2, var = c("eta","sigma","etaBeta"))
``` 

```{r}
samplesPlot(samples2, var = "betaGroups[2]")
samplesPlot(samples2, var = "muGroups[1]")
samplesPlot(samples2, var = "sigma")
``` 

Zaradi centriranosti se dokaj lepo gibljejo in so zgosceni. 

```{r}
effectiveSize(samples2)
```

```{r}
max(abs(cor(samples2)[cor(samples2)!=1]))
```

